{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Contents\n",
    "Fill out this notebook as part of your final project submission.\n",
    "\n",
    "**You will have to complete both the Code and Project Write-up sections.**\n",
    "- The [Code](#Code) is where you will write a **pulse rate algorithm** and already includes the starter code.\n",
    "   - Imports - These are the imports needed for Part 1 of the final project. \n",
    "     - [glob](https://docs.python.org/3/library/glob.html)\n",
    "     - [numpy](https://numpy.org/)\n",
    "     - [scipy](https://www.scipy.org/)\n",
    "- The [Project Write-up](#Project-Write-up) to describe why you wrote the algorithm for the specific case.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "You will be using the **Troika**[1] dataset to build your algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data. The starter code contains a function to help load these files.\n",
    "\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "def BandpassFilter(signal, pass_band, fs):\n",
    "    \"\"\"Bandpass Filter.\n",
    "    \n",
    "    Args:\n",
    "        signal: (np.array) The input signal\n",
    "        pass_band: (tuple) The pass band. Frequency components outside \n",
    "            the two elements in the tuple will be removed.\n",
    "        fs: (number) The sampling rate of <signal>\n",
    "        \n",
    "    Returns:\n",
    "        (np.array) The filtered signal\n",
    "    \"\"\"\n",
    "    b, a = sp.signal.butter(3, pass_band, btype='bandpass', fs=fs)\n",
    "    return sp.signal.filtfilt(b, a, signal)\n",
    "\n",
    "def PreprocessSignal(ppg, accx, accy, accz):\n",
    "    \"\"\"Preprocess Signal.\n",
    "    \n",
    "    Apply Bandpass filter with 40-240BPM range to raw signals.\n",
    "    \n",
    "    Args:\n",
    "        numpy arrays for raw ppg, accx, accy, accz signals.\n",
    "        \n",
    "    Returns:\n",
    "        numpy arrays for filtered ppg, accx, accy, accz signals.\n",
    "    \"\"\"    \n",
    "    fs=125\n",
    "    freq_filter=(40/60,240/60)\n",
    "    ppg=BandpassFilter(ppg, freq_filter, fs)\n",
    "    accx=BandpassFilter(accx, freq_filter, fs)\n",
    "    accy=BandpassFilter(accy, freq_filter, fs)\n",
    "    accz=BandpassFilter(accz, freq_filter, fs)\n",
    "    return ppg, accx, accy, accz\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    \"\"\"Estimate pulse rate from PPG and accelerometer signals. \n",
    "    \n",
    "    Calculate MAE errors and confidence.\n",
    "        \n",
    "    Args:\n",
    "        Paths for PPG and accelerometer signal files and pulse rate reference.\n",
    "        \n",
    "    Returns:\n",
    "        Return per-estimate mean absolute error and confidence as a 2-tuple of numpy arrays.\n",
    "    \"\"\"    \n",
    "    # Load data using LoadTroikaDataFile\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "    ppg, accx, accy, accz = PreprocessSignal(ppg, accx, accy, accz)\n",
    "    \n",
    "    # Compute pulse rate estimates and estimation confidence.\n",
    "    window_len=600\n",
    "    fs=125\n",
    "    # Generate outputs every 2s\n",
    "    window_shift=fs*2\n",
    "    \n",
    "    # pr:estimated pulse rate\n",
    "    pr=[]\n",
    "    confidence=[]\n",
    "    \n",
    "    for i in range(0, len(ppg) - window_len, window_shift):\n",
    "        ppg_seg=ppg[i: i + window_len]\n",
    "        accx_seg=accx[i: i + window_len]\n",
    "        accy_seg=accy[i: i + window_len]\n",
    "        accz_seg=accz[i: i + window_len]\n",
    "        \n",
    "        # Run fast Fourier transform on each window\n",
    "        freqs = np.fft.rfftfreq(window_len, 1/fs)\n",
    "        fft_p = abs(np.fft.rfft(ppg_seg, 600))\n",
    "        fft_x = abs(np.fft.rfft(accx_seg, 600))\n",
    "        fft_y = abs(np.fft.rfft(accy_seg, 600))\n",
    "        fft_z = abs(np.fft.rfft(accz_seg, 600))\n",
    "        \n",
    "        fft_acc=np.sqrt(np.square(fft_x)+np.square(fft_y)+np.square(fft_z))\n",
    "        \n",
    "        # Find peaks within normal pulse frequency from PPG and accelerometer signals after fft\n",
    "        fftp_pks_raw,fftp_h_raw = sp.signal.find_peaks(fft_p,height=250)\n",
    "        fftp_pks_raw=freqs[fftp_pks_raw]\n",
    "        fftp_h_raw=fftp_h_raw['peak_heights']\n",
    "\n",
    "        fftp_f_range=(fftp_pks_raw>=40/60)&(fftp_pks_raw<=240/60)\n",
    "        fftp_pks=fftp_pks_raw[fftp_f_range]\n",
    "        fftp_h=fftp_h_raw[fftp_f_range]    \n",
    "\n",
    "        fftacc_pks_raw,fftacc_h_raw = sp.signal.find_peaks(fft_acc,height=2)\n",
    "        fftacc_pks_raw=freqs[fftacc_pks_raw]\n",
    "        fftacc_h_raw=fftacc_h_raw['peak_heights']\n",
    "\n",
    "        fftacc_f_range=(fftacc_pks_raw>=40/60)&(fftacc_pks_raw<=240/60)\n",
    "        fftacc_pks=fftacc_pks_raw[fftacc_f_range]\n",
    "        fftacc_h=fftacc_h_raw[fftacc_f_range]\n",
    "\n",
    "        \n",
    "        # If PPG frequencies peaks were found, compare the top-4 dominant peaks with the top-4 dominant peaks \n",
    "        # in accelerometer signals and remove shared peaks to reduce movement artifacts.\n",
    "        if len(fftp_pks)>0:\n",
    "            fftp_pks=fftp_pks[np.argsort(-fftp_h)]\n",
    "            fftp_h=fftp_h[np.argsort(-fftp_h)]    \n",
    "            if len(fftp_pks)>4:\n",
    "                fftp_pks=fftp_pks[:4]\n",
    "                fftp_h=fftp_h[:4]\n",
    "\n",
    "            if len(fftacc_pks)>0:\n",
    "                fftacc_pks=fftacc_pks[np.argsort(-fftacc_h)]\n",
    "                fftacc_h=fftacc_h[np.argsort(-fftacc_h)]\n",
    "            if len(fftacc_pks)>4:\n",
    "                fftacc_pks=fftacc_pks[:4]\n",
    "                fftacc_h=fftacc_h[:4]\n",
    "\n",
    "            unique_f=[x for x in fftp_pks if not x in fftacc_pks]\n",
    "            if len(unique_f)>0:\n",
    "                pr_f=unique_f[0]\n",
    "            else:\n",
    "                pr_f=fftp_pks[0]\n",
    "        \n",
    "        # If no peak was found, use the strongest PPG frequency as the estimate.\n",
    "        else:\n",
    "            freqs_range=(freqs>=40/60)&(freqs<=240/60)\n",
    "            freqs_filtered=freqs[freqs_range]\n",
    "            fft_p_filtered=fft_p[freqs_range]\n",
    "\n",
    "            pr_f=freqs_filtered[np.argsort(-fft_p_filtered)][0]\n",
    "        \n",
    "        # Pulse rate usually doesn't change significantly within 2s, I limit the change to 1.1 times to smooth the signal.\n",
    "        pr_r=pr_f*60\n",
    "        if len(pr)>0:\n",
    "            if pr_r>1.1*pr[-1]:\n",
    "                pr_r=1.1*pr[-1]\n",
    "            if pr_r<pr[-1]/1.1:\n",
    "                pr_r=pr[-1]/1.1\n",
    "\n",
    "        pr.append(pr_r)\n",
    "        \n",
    "        # Find the nearest peak of the estimated pulse frequency and calculate the confidence.\n",
    "        delta_fftp_pks_raw=abs(fftp_pks_raw-pr_r/60)\n",
    "        confidence.append(fftp_h_raw[delta_fftp_pks_raw.argmin()]/sum(fftp_h_raw))\n",
    "\n",
    "    \n",
    "    # Return per-estimate mean absolute error and confidence as a 2-tuple of numpy arrays.\n",
    "    reference=sp.io.loadmat(ref_fl)['BPM0'].reshape((1,-1))[0]\n",
    "    errors=abs(pr[:len(reference)]-reference)\n",
    "    confidence=np.array(confidence[:len(reference)])\n",
    "    \n",
    "    return errors, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.127948293870112"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Project Write-up\n",
    "\n",
    "Answer the following prompts to demonstrate understanding of the algorithm you wrote for this specific context.\n",
    "\n",
    "> - **Code Description** - Include details so someone unfamiliar with your project will know how to run your code and use your algorithm. \n",
    "> - **Data Description** - Describe the dataset that was used to train and test the algorithm. Include its short-comings and what data would be required to build a more complete dataset.\n",
    "> - **Algorithhm Description** will include the following:\n",
    ">   - how the algorithm works\n",
    ">   - the specific aspects of the physiology that it takes advantage of\n",
    ">   - a describtion of the algorithm outputs\n",
    ">   - caveats on algorithm outputs \n",
    ">   - common failure modes\n",
    "> - **Algorithm Performance** - Detail how performance was computed (eg. using cross-validation or train-test split) and what metrics were optimized for. Include error metrics that would be relevant to users of your algorithm. Caveat your performance numbers by acknowledging how generalizable they may or may not be on different datasets.\n",
    "\n",
    "Your write-up goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Code Description** \n",
    "\n",
    "The code can be used to estimate pulse rates according to PPG and accelerometer signals. The performance of the estimation is then evaluated. Each function is described by the docstrings. \"Evaluate\" function should be ran to initiate the whole process.\n",
    "\n",
    "\n",
    "- **Data Description** \n",
    "\n",
    "Troika dataset was used to validate and test the algorithm. PPG signals, three-axis acceleration signals, and one-channel ECG signals were simultaneously recorded from 12 subjects with age from 18 to 35. Each recording is 5 min during rest and different running speeds. The ground-truth of heart rate is calculated from the ECG signal.\n",
    "\n",
    "The recordings are relatively short. Longer recordings and recordings during other activities are needed to build a more complete dataset. More information of the subjects will also be helpful.\n",
    "\n",
    "\n",
    "- **Algorithm Description** \n",
    "\n",
    "The amount of blood within wrist capillaries is affected by ventricle contractions. PPG sensor measures the light absorption by red blood cells as an indication of the amount of blood to estimate the pulse rate.\n",
    "\n",
    "Arm motion can affect PPG sensor measurements. To reduce motion-caused noise, arm acceleration is monitored at the same time. Fast Fourier transform are performed in both PPG and accelerometer signals in 4.8s window every 2s. The top-4 strongest frequency peaks within normal pulse rate range are compared between the two channels. The strongest peak appears in PPG signal but no in accelerometer signal is used as the estimates. If all peaks overlap, the strongest peak in PPG signal is used. The pulse rate estimate of each time point is also restricted to 1.1 times of the previous estimate.\n",
    "\n",
    "The algorithm generates pulse rate estimates and confidence every 2s. Confidence is measured as the percentage of energy in the frequency spectrum near the pulse frequency estimate. The energy near the pulse frequency estimate is an indication of signal strength. The energy elsewhere is an indication of noise strength. Their ratio can be a measurement for the confidence of estimates.\n",
    "\n",
    "The algorithm may not be accurate if pulse rate changes rapidly in short time.\n",
    "\n",
    "The algorithm will likely fail when arm acceleration is very strong and irregular. Finger movements may not be captured by accelerometer, which also affects the accuracy of the algorithm.\n",
    "  \n",
    "  \n",
    "- **Algorithm Performance** \n",
    "\n",
    "Mean absolute error of the best 90% of the estimates is used to evaluate algorithm performance. The algorithm can be used in other datasets with PPG and three-axis acceleration signals during rest and running.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Next Steps\n",
    "You will now go to **Test Your Algorithm** to apply a unit test to confirm that your algorithm met the success criteria. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
